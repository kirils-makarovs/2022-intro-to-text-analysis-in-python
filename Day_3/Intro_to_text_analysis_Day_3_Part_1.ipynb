{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Intro_to_text_analysis_Day_3_Part_1.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1J_VwH0BZl_NnrWBHnK-cScNcjzQWZXEG","authorship_tag":"ABX9TyObcuygWi0MIew7GS1Okwmc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"EWB457PFT4J2"},"source":["# **Introduction to text analysis in Python. Day 3 Part 1**\n","\n","## *Dr Kirils Makarovs*\n","\n","## *k.makarovs@exeter.ac.uk*\n","\n","## *University of Exeter Q-Step Centre*\n","\n","---\n"]},{"cell_type":"markdown","metadata":{"id":"6b_C8WzNqV4z"},"source":["# **Welcome to Day 3 Part 1!**"]},{"cell_type":"markdown","metadata":{"id":"DmD95g7Na2wJ"},"source":["## **Today, we are going to look at:**\n","\n","+ Descriptive text analysis (continuation)\n","+ Text preprocessing\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ygnZsPQr3-mL"},"source":["# **Descriptive text analysis (continuation)**\n"]},{"cell_type":"code","metadata":{"id":"Gi-tODR_pzmZ"},"source":["# Import the necessary libraries\n","\n","import pandas as pd # data analysis and management library\n","import numpy as np # multi-dimensional arrays\n","\n","# Data visualization\n","\n","import seaborn as sns # easy-syntax plots\n","import matplotlib.pyplot as plt # deep-level library used to tweak the details of the seaborn plots\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Let's upload the updated dataset (fakenews_upd.csv) into the current Google Colab session\n","\n","from google.colab import files\n","\n","uploaded = files.upload()\n"],"metadata":{"id":"LZnGdjUqf6od"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Getting the dataset\n","\n","df = pd.read_csv('fakenews_upd.csv')\n","\n","df\n"],"metadata":{"id":"J5Ix109fiHTK"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZeLupr7heX8q"},"source":["# Some helpful commands to get to know the dataset\n","\n","type(df) # object type - pandas.core.frame.DataFrame\n","\n","df.shape # number of rows and columns\n","\n","df.columns # column names\n","\n","df.index # indeces\n","\n","df.info() # summary of the variables in the dataset\n","\n","df.head() # get the top 5 rows of the dataset\n","\n","df.tail() # get the last 5 rows of the dataset\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's take a look at some examples of **descriptive analysis** that one can run with the existing variables\n","\n","We will start by inspecting the characterstics of the newspaper articles altogether, and then scrutinize the differences between the **real** and **fake** newspaper article titles"],"metadata":{"id":"i-_Xv5FtOxPd"}},{"cell_type":"markdown","metadata":{"id":"yf2BT7PTOdAy"},"source":["---\n","\n","## **Are number of characters, number of words, average word length and number of capitalized words correlated with each other?**\n"]},{"cell_type":"markdown","source":["<figure>\n","<left>\n","<img src=https://www.ncl.ac.uk/webtemplate/ask-assets/external/maths-resources/images/R_value.png width=\"2000\">\n","</figure>"],"metadata":{"id":"GTFw1S0KgaDN"}},{"cell_type":"code","source":["# Import the necessary command first\n","\n","from scipy.stats import pearsonr # Pearson's r\n"],"metadata":{"id":"RRljWDgRU5It"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Draw a simple scatterplot of number of words vs. average word length\n","\n","plt.figure(figsize = (14, 9))\n","\n","sns.scatterplot(data = df, x = 'n_words', y = 'avg_word_length')\n","\n","plt.title('The relationship between number of words and average word length', fontsize = 20)\n","plt.xlabel('Number of words', fontsize = 15)\n","plt.ylabel('Average word length', fontsize = 15)\n","\n","plt.show()\n"],"metadata":{"id":"fidyr8fvhiaN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Use sns.lmplot() if you want to have a trend line on top of a scatterplot\n","# and split by article type\n","\n","plt.figure(figsize = (14, 9))\n","\n","sns.lmplot(data = df,\n","            x = 'n_words',\n","            y = 'avg_word_length',\n","            hue = 'label',\n","            palette = \"Set1\",\n","            height = 8, # height of the graph\n","            aspect = 1.5) # width = height * aspect\n","\n","plt.title('The relationship between number of words and average word length\\nby newspaper article type', fontsize = 20)\n","plt.xlabel('Number of words', fontsize = 15)\n","plt.ylabel('Average word length', fontsize = 15)            \n","\n","plt.show()\n"],"metadata":{"id":"VivkshtO9g2I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Obtain Pearson's correlation coefficient and its p-value between these two variables\n","\n","corr_coef, p_value = pearsonr(df['n_words'], df['avg_word_length'])\n","\n","corr_coef\n","\n","p_value\n","\n","round(corr_coef, 2)\n","\n","print(f'The Pearson correlation coefficient value is: {round(corr_coef, 2)}')\n","\n","print(f'The Pearson correlation coefficient p-value is: {round(p_value, 2)}')\n"],"metadata":{"id":"Yfeql3i8VDBz"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6Y815pYAd9dI"},"source":["# Correlation matrix: use panda's .corr() method\n","\n","# .corr() provides a correlation matrix even if only two variables are presented:\n","\n","df[['n_words', 'avg_word_length']].corr()\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Let's get a correlation matrix of all the variables of interest\n","\n","corr_matrix = df[['n_char', 'n_words', 'avg_word_length', 'n_cap_words']].corr()\n","\n","corr_matrix\n","\n","round(corr_matrix, 2)\n"],"metadata":{"id":"GW0kf2sKc12-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# You can visualize the correlation matrix\n","# (which is essentially a dataframe - check type(corr_matrix)) by using seaborn's heatmap\n","\n","type(corr_matrix) # pandas.core.frame.DataFrame\n","\n","plt.figure(figsize = (14, 9))\n","\n","sns.heatmap(corr_matrix, annot = True)\n","\n","plt.show()\n","\n","# Check out more arguments of the seaborn heatmap here - https://seaborn.pydata.org/generated/seaborn.heatmap.html\n"],"metadata":{"id":"gdMAKARnd52M"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["If you want to have p-values on top of the correlation coefficient values, you can use one of the community solutions provided [here](https://stackoverflow.com/questions/24432101/correlation-coefficients-and-p-values-for-all-pairs-of-rows-of-a-matrix)."],"metadata":{"id":"6ZTkV48Y4LJ9"}},{"cell_type":"markdown","metadata":{"id":"-5d1EYee89f9"},"source":["---\n","\n","## **Inspecting how real newspaper articles titles are different from the fake ones**\n"]},{"cell_type":"code","source":["# See how many fake and real newspaper article titles are there in the dataset\n","\n","df['label'].value_counts(normalize = True)\n"],"metadata":{"id":"j2TmF-A09Lmq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f430WHxpcbMT"},"source":["### **Aggregated statistics**\n","\n","<figure>\n","<left>\n","<img src=https://miro.medium.com/max/1400/0*XVlrOuSBNKwIZpPj.png width=\"500\">\n","</figure>\n","\n","**[Image source](https://towardsdatascience.com/7-pandas-functions-that-i-use-the-most-b83ddbaf53bf)**\n","\n","**Aggregated analysis** implies that you get some statistic (e.g. mean or median) of your main variable **separately for groups of observations** defined by some **other variable**\n","\n","(also known as **Split-Apply-Combine** technique)\n","\n","Your main variable should **continuous**, whereas grouping variable - **categorical** \n","\n","For example:\n","\n","+ mean income for men and women\n","+ median level of life satisfaction for young, middle-aged, and elderly people\n","+ 25% and 75% percentiles of anxiety scale for 1st, 2nd, and 3rd-year students\n","\n","The process of getting **aggregated statistics** requires two steps:\n"," + first group your data via .groupby() method,\n"," + then get aggregated values"]},{"cell_type":"code","source":["# Let's get the mean number of characters per fake and real newspaper article titles\n","\n","df.groupby('label')['n_char'].mean()\n","\n","# Fake titles seem to be longer than the real ones\n"],"metadata":{"id":"6bKBwrI_K2o8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Let's visualize the relatiosnhip between the newspaper article title type\n","# and average number of characters by drawing a bar plot\n","\n","# A bar plot represents an estimate of central tendency (e.g. mean) for a numeric variable\n","# with the height of each rectangle and provides some indication of the uncertainty\n","# around that estimateusing error bars.\n","\n","# See more examples of `seaborn` bar plots [here](https://seaborn.pydata.org/generated/seaborn.barplot.html).\n","\n","plt.figure(figsize = (14, 9))\n","\n","sns.barplot(data = df, x = 'label', y = 'n_char')\n","\n","plt.title('The average number of characters\\nby newspaper article title type', fontsize = 20)\n","plt.xlabel('Newspaper article title type ', fontsize = 15)\n","plt.ylabel('Average number of characters per title', fontsize = 15)  \n","\n","plt.show()\n"],"metadata":{"id":"CVHBh08IZ4XU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Getting the mean and standard deviation of number of words per fake and real newspaper article titles\n","\n","df.groupby('label')['n_words'].agg(['mean', 'std'])\n"],"metadata":{"id":"5NGvra04LNDh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# What about the average word length?\n","\n","df.groupby('label')['avg_word_length'].agg(['mean', 'median', 'std'])\n","\n","# Seems pretty even!\n"],"metadata":{"id":"RKcgTPTpLuux"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JVJkBNYZMuhn"},"source":["---\n","\n","## **What about the proportion of titles that include numerical values?**\n"]},{"cell_type":"code","source":["# Originally, the variable n_num (number of numerical values) has got three values - 0, 1, and 3.\n","\n","df['n_num'].value_counts(normalize = True)\n","\n","df['n_num'].value_counts()\n","\n","# However, since there is only 1% of titles that contain 2 numerical values, let's make this variable binary:\n","\n","# 0 - no numerical values\n","# 1 - one or more numerical values\n"],"metadata":{"id":"9xnOsE8IMjH0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Let's create a new variable called n_num_bin and use the np.where() method\n","\n","df['n_num_bin'] = np.where(df['n_num'] == 0, 'No numerical values', 'Some numerical values')\n","\n","df['n_num_bin'].value_counts(normalize = True)\n"],"metadata":{"id":"Dj2LHjdMNrMM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Now let's run a crosstab to see what is the proportion of titles that have at least some numerical values\n","# among real and fake newspaper article titles\n","\n","pd.crosstab(df['label'], df['n_num_bin'],\n","            normalize = 'index', margins = True) * 100 # row proportions, assuming that type of title affects number of numerical values\n","\n","# Is there a relationship between the newspaper article title type and number of numerical values?\n"],"metadata":{"id":"vHYlnMgpMWsx"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bBiwJ9pyBdJM"},"source":["# Let's visualize the crosstab!\n","\n","# We will visualize this crosstab with a help of baseline matplotlib (not seaborn)\n","\n","# We need a crosstab with proportions but with no margins, so let's create it and save as a separate object\n","\n","crosstab = pd.crosstab(df['label'], df['n_num_bin'], normalize = 'index')\n","\n","# For other variables, you can recycle this code entirely, but make sure that you\n","# provide a correct crosstab to the .plot() command,\n","\n","# Defining a figure with a single plot of sizes 12 and 7\n","\n","f, ax = plt.subplots(nrows = 1, ncols = 1, figsize=(12, 7))\n","\n","# Drawing a plot straight from the crosstab created above\n","\n","crosstab.plot(kind = 'bar', # bar plot\n","              stacked = True, # stacking proportions from a crosstab\n","              rot = 0, # no rotation for X ticks\n","              ax = ax) # linking a figure created above with the plot of a crosstab\n","\n","\n","plt.title('Proportion of titles that include numerical values\\nby newspaper article title type', fontsize = 20)\n","plt.xlabel('Newspaper article title type', fontsize = 15)\n","plt.ylabel('Proportion of titles\\n with and without numerical values', fontsize = 15)\n","\n","plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Exercise**\n","\n","Get the dataset and try out different types of descriptive analysis that you've just learned!"],"metadata":{"id":"3GxQkZ3fBoJO"}},{"cell_type":"markdown","metadata":{"id":"M8g6p6TF8C_A"},"source":["# **That's the end of Day 3 Part 1!**"]}]}