{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Intro_to_text_analysis_Day_4_part_2.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1J_VwH0BZl_NnrWBHnK-cScNcjzQWZXEG","authorship_tag":"ABX9TyNJStIu0Rxqj1v82m2wqMps"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"EWB457PFT4J2"},"source":["# **Introduction to text analysis in Python. Day 4 Part 2**\n","\n","## *Dr Kirils Makarovs*\n","\n","## *k.makarovs@exeter.ac.uk*\n","\n","## *University of Exeter Q-Step Centre*\n","\n","---\n"]},{"cell_type":"markdown","metadata":{"id":"6b_C8WzNqV4z"},"source":["# **Welcome to Day 4 Part 2!**"]},{"cell_type":"markdown","metadata":{"id":"DmD95g7Na2wJ"},"source":["## **Today, we are going to look at:**\n","\n","+ *Bag-of-Words* model and `CountVectorizer`\n","+ Lexicon-based sentiment analysis\n","\n","---\n","\n"]},{"cell_type":"markdown","source":["## **Preparatory steps first**"],"metadata":{"id":"RK2l5IdsoWxI"}},{"cell_type":"code","source":["# Importing some of the required libraries\n","\n","import pandas as pd\n","import numpy as np\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n"],"metadata":{"id":"PWyNUp18oTL6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# This will ensure that all rows of the dataframe will be shown \n","\n","pd.set_option('display.max_rows', None)\n"],"metadata":{"id":"NyySfKQdxQTF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Uploading ted.csv and ted_clean.csv into the current Google Colab session\n","\n","from google.colab import files\n","\n","uploaded = files.upload()\n"],"metadata":{"id":"rc_6ziYfoTL7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Getting both datasets\n","\n","ted = pd.read_csv('ted.csv')\n","\n","ted_clean = pd.read_csv('ted_clean.csv')\n"],"metadata":{"id":"dLPJX8gxoTL7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **2. Lexicon-based sentiment analysis**\n","\n","<figure>\n","<left>\n","<img src=https://d3caycb064h6u1.cloudfront.net/wp-content/uploads/2021/06/sentimentanalysishotelgeneric-2048x803-1.jpg  width=\"700\">\n","</figure>\n","\n","[Image source](https://expressanalytics.com/blog/social-media-sentiment-analysis/)\n","\n","\n","`Textblob`'s `.sentiment` method returns two values: *polarity* and *subjectivity*\n","\n","The **polarity** score is a value within the range **[-1.0, 1.0]**\n","+ -1 - negative sentiment\n","+ 0 - neutral sentiment\n","+ +1 - positive sentiment\n","\n","The **subjectivity** is a float within the range **[0.0, 1.0]**, where 0.0 is *very objective* and 1.0 is *very subjective*\n","\n","*Subjective sentences* express author's feelings, views, beliefs, opinions\n","\n","*Objective sentences* communicate the facts rhather than beliefs\n","\n","**Lexicon-based** sentiment analysis implies that there is a pre-defined set of categorized words, that the lemmas of our document are compared to\n","\n","Each word in a pre-defined dictionary is classified either as a negative, neutral, positive, with respective intensity of a sentiment\n","\n","There are two algorithms that can be implemented:\n","\n","+ *PatternAnalyzer* - a default classifier that is built on the pattern library\n","\n","+ *NaiveBayesAnalyzer* - an NLTK model trained on a movie reviews corpus\n","\n","You can read [this](https://www.cs.rit.edu/usr/local/pub/GraduateProjects/2165/fjk9481/Report.pdf) report to get a better understanding of how `TextBlob`'s sentiment analysis works "],"metadata":{"id":"opYfWQcUwif8"}},{"cell_type":"code","source":["from textblob import TextBlob # importing TextBlob\n"],"metadata":{"id":"vEQ2QxLSzIGL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Running sentiment analysis on a single TED talk**"],"metadata":{"id":"Uh_FRLfp4TaU"}},{"cell_type":"code","source":["# Getting a single TED talk. We will use unpreprocessed text entry for now\n","\n","single_talk = ted['transcript'][0]\n","\n","single_talk\n"],"metadata":{"id":"FCYbEZ960FLr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Making it a TextBlob object\n","\n","single_talk_blob = TextBlob(single_talk)\n","\n","single_talk_blob\n","\n","type(single_talk_blob) # textblob.blob.TextBlob\n"],"metadata":{"id":"X7tif2XS0y5j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Getting the polarity and subjectivity of the TED talk\n","\n","single_talk_blob.sentiment # Sentiment(polarity=0.2574747337056497, subjectivity=0.47191676855799003)\n","\n","# Polarity separately\n","\n","single_talk_blob.polarity # 0.2574747337056497\n","\n","# Subjectivity separately\n","\n","single_talk_blob.subjectivity # 0.47191676855799003\n"],"metadata":{"id":"3xvtY1ea0623"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Which lemmas contributed to the scores of polarity and subjectivity?\n","\n","single_talk_blob.sentiment_assessments\n"],"metadata":{"id":"tDGvXxcCfkhs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Running sentiment analysis on a corpus of raw and preprocessed TED talks**"],"metadata":{"id":"48tmCjTc5ygd"}},{"cell_type":"code","source":["# Let's define a function that return the polarity and subjectivity score for a text entry\n","\n","def get_polarity_subjectivity(text):\n","\n","  # Making text a TextBlob object\n","  text_blob = TextBlob(text)\n","\n","  # Getting its polarity, rounded to 2 decimals\n","  polarity = round(text_blob.polarity, 2)\n","\n","  # Getting its subjectivity, rounded to 2 decimals\n","  subjectivity = round(text_blob.subjectivity, 2)\n","\n","  # Returning both objects as a list\n","  return([polarity, subjectivity])\n"],"metadata":{"id":"NI3ebRhy6Gky"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Running the above created function on a corpus of raw TED talks\n","\n","ted_scores = ted['transcript'].apply(lambda x: get_polarity_subjectivity(x))\n","\n","ted_scores.head(10)\n"],"metadata":{"id":"xsSBwiLH62OA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Running the same function but on a corpus of preprocessed TED talks\n","\n","ted_clean_scores = ted_clean['transcript'].apply(lambda x: get_polarity_subjectivity(x))\n","\n","ted_clean_scores.head(10)\n"],"metadata":{"id":"lNGwG-T18opW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Now we have two pandas Series, where each rows contains a list of values\n","\n","type(ted_scores) # pandas.core.series.Series\n","type(ted_clean_scores) # pandas.core.series.Series\n","\n","ted_scores[0] # [0.26, 0.47]\n","ted_clean_scores[0] # [0.32, 0.52]\n"],"metadata":{"id":"WwYRhodX9kjV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Now let's convert it all into a dataframe with 4 columns:\n","\n","# ted_raw_pol - polarity score of unpreprocessed TED talks\n","# ted_raw_sub - subjectivity score of unpreprocessed TED talks\n","# ted_clean_pol - polarity score of preprocessed TED talks\n","# ted_clean_sub - subjectivity score of preprocessed TED talks\n","\n","scores_raw = pd.DataFrame(ted_scores.tolist(), columns = ['ted_raw_pol', 'ted_raw_sub'])\n","\n","scores_clean = pd.DataFrame(ted_clean_scores.tolist(), columns = ['ted_clean_pol', 'ted_clean_sub'])\n","\n","df_scores = pd.concat([scores_raw, scores_clean], axis = 1) # concatenate by columns\n","\n","df_scores.head(10)\n"],"metadata":{"id":"tIDU9525-EQs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Are the scores on the preprocessed talks any different from the scores on the raw talks?**"],"metadata":{"id":"Ezw4tMh7B1yg"}},{"cell_type":"code","source":["# Obtaining the correlation matrix between the variables\n","\n","round(df_scores.corr(), 2)\n"],"metadata":{"id":"rayquCLqRKTf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Getting the mean and standard deviation of the polarity and subjectivity scores\n","\n","round(df_scores.agg(['mean', 'std']).transpose(), 2)\n","\n","# The range of polarity scores is from -1 to 1\n","# The range of subjectivity scores is from 0 to 1\n"],"metadata":{"id":"KybDoaGJbb_v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Drawing multiple regression graphs on one plot\n","\n","figure, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows = 2,\n","                                                ncols = 2,\n","                                                figsize=(20, 15))\n","\n","sns.regplot(data = df_scores, x = 'ted_raw_pol', y = 'ted_raw_sub', ax = ax1)\n","sns.regplot(data = df_scores, x = 'ted_clean_pol', y = 'ted_clean_sub', ax = ax2)\n","\n","sns.regplot(data = df_scores, x = 'ted_raw_pol', y = 'ted_clean_pol', ax = ax3)\n","sns.regplot(data = df_scores, x = 'ted_raw_sub', y = 'ted_clean_sub', ax = ax4)\n","\n","\n","ax1.set_title('The relationship between \\nRAW polarity and RAW subjectivity', fontsize = 15)\n","ax2.set_title('The relationship between \\nCLEAN polarity and CLEAN subjectivity', fontsize = 15)\n","ax3.set_title('The relationship between \\nRAW polarity and CLEAN polarity', fontsize = 15)\n","ax4.set_title('The relationship between \\nRAW subjectivity and CLEAN subjectivity', fontsize = 15)\n","\n","sns.set_style('whitegrid')\n","\n","plt.show()\n"],"metadata":{"id":"WQ3fMzaUSTA3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Identifying the most positive and subjective TED talks**"],"metadata":{"id":"jfuNxQQ5Rcps"}},{"cell_type":"code","source":["# We first need to concatenate the columns with scores to the dataframe with TED talks\n","\n","ted_upd = pd.concat([ted, df_scores], axis = 1).drop('url', axis = 1)\n","\n","ted_upd.head(10)\n"],"metadata":{"id":"qQlPc2rMSDL3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Which TED talk has the most positive sentiment?\n","\n","max_score = ted_upd['ted_clean_pol'].max()\n","\n","max_score_id = ted_upd['ted_clean_pol'].idxmax()\n","\n","print(f'The most positive TED talk has the polarity value of {max_score}')\n","print('\\nHere it is:\\n')\n","\n","ted_upd.iloc[max_score_id, 0]\n"],"metadata":{"id":"uCw4im6_VqYY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Which TED talk is the most subjective one?\n","\n","max_score = ted_upd['ted_clean_sub'].max()\n","\n","max_score_id = ted_upd['ted_clean_sub'].idxmax()\n","\n","print(f'The most subjective TED talk has the subjectivity value of {max_score}')\n","print('\\nHere it is:\\n')\n","\n","ted_upd.iloc[max_score_id, 0]\n"],"metadata":{"id":"Qq6bCbYtaDs1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M8g6p6TF8C_A"},"source":["# **That's the end of Day 4 Part 2!**"]}]}